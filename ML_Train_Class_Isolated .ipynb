{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703d6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANITrainer:\n",
    "    def __init__(self, model, batch_size, learning_rate, epoch, l2):\n",
    "        self.model = model\n",
    "        \n",
    "        num_params = sum(item.numel() for item in model.parameters())\n",
    "        print(f\"{model.__class__.__name__} - Number of parameters: {num_params}\")\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=l2)\n",
    "        self.epoch = epoch\n",
    "    \n",
    "    def train(self, train_data, val_data, early_stop=True, draw_curve=True):\n",
    "        self.model.train()\n",
    "        \n",
    "        # init data loader\n",
    "        print(\"Initialize training data...\")\n",
    "        train_data_loader = DataLoader(dataset=train_data, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        # definition of loss function: MSE is a good choice! \n",
    "        loss_func = nn.MSELoss()\n",
    "        \n",
    "        # record epoch losses\n",
    "        train_loss_list = []\n",
    "        val_loss_list = []\n",
    "        lowest_val_loss = np.inf\n",
    "        \n",
    "        for i in tqdm(range(self.epoch), leave=True):\n",
    "            train_epoch_loss = 0.0\n",
    "            for train_data_batch in train_data_loader:\n",
    "                \n",
    "                # compute energies\n",
    "                pred = self.model(train_data_batch[0])\n",
    "                \n",
    "                # compute loss\n",
    "                batch_loss = loss_func(pred, train_data_batch[1])\n",
    "                \n",
    "                # do a step\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                batch_importance = train_data_batch[1].shape[0] / len(train_data)\n",
    "                train_epoch_loss += batch_loss.detach().cpu().item() * batch_importance\n",
    "            \n",
    "            # use the self.evaluate to get loss on the validation set \n",
    "            val_epoch_loss = self.evaluate(val_data)\n",
    "            \n",
    "            # append the losses\n",
    "            train_loss_list.append(train_epoch_loss)\n",
    "            val_loss_list.append(val_epoch_loss)\n",
    "            \n",
    "            if early_stop:\n",
    "                if val_epoch_loss < lowest_val_loss:\n",
    "                    lowest_val_loss = val_epoch_loss\n",
    "                    weights = self.model.state_dict()\n",
    "        \n",
    "        if draw_curve:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 4), constrained_layout=True)\n",
    "            ax.set_yscale(\"log\")\n",
    "            # Plot train loss and validation loss\n",
    "            ax.plot(np.arange(self.epoch), train_loss_list, label='Train')\n",
    "            ax.plot(np.arange(self.epoch), val_loss_list, label='Validation')\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(\"# Batch\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "        \n",
    "        if early_stop:\n",
    "            self.model.load_state_dict(weights)\n",
    "        \n",
    "        return train_loss_list, val_loss_list\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data, draw_plot=False):\n",
    "        \n",
    "        # init data loader\n",
    "        data_loader = DataLoader(dataset=data, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        # init loss function\n",
    "        loss_func = nn.MSELoss()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        if draw_plot:\n",
    "            true_energies_all = []\n",
    "            pred_energies_all = []\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for batch_data in data_loader:\n",
    "                \n",
    "                # compute energies\n",
    "                pred = self.model(batch_data[0])\n",
    "                \n",
    "                # compute loss\n",
    "                batch_loss = loss_func(pred, batch_data[1])\n",
    "\n",
    "                batch_importance = batch_data[1].shape[0] / len(train_data)\n",
    "                total_loss += batch_loss.detach().cpu().item() * batch_importance\n",
    "                \n",
    "                if draw_plot:\n",
    "                    true_energies_all.append(true_energies.detach().cpu().numpy().flatten())\n",
    "                    pred_energies_all.append(pred_energies.detach().cpu().numpy().flatten())\n",
    "\n",
    "        if draw_plot:\n",
    "            true_energies_all = np.concatenate(true_energies_all)\n",
    "            pred_energies_all = np.concatenate(pred_energies_all)\n",
    "            # Report the mean absolute error\n",
    "            # The unit of energies in the dataset is hartree\n",
    "            # please convert it to kcal/mol when reporting the mean absolute error\n",
    "            # 1 hartree = 627.5094738898777 kcal/mol\n",
    "            # MAE = mean(|true - pred|)\n",
    "            hartree2kcalmol = 627.5094738898777\n",
    "            mae = np.mean(np.abs(true_energies_all*hartree2kcalmol - pred_energies_all*hartree2kcalmol))\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 4), constrained_layout=True)\n",
    "            ax.scatter(true_energies_all, pred_energies_all, label=f\"MAE: {mae:.2f} kcal/mol\", s=2)\n",
    "            ax.set_xlabel(\"Ground Truth\")\n",
    "            ax.set_ylabel(\"Predicted\")\n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            vmin, vmax = min(xmin, ymin), max(xmax, ymax)\n",
    "            ax.set_xlim(vmin, vmax)\n",
    "            ax.set_ylim(vmin, vmax)\n",
    "            ax.plot([vmin, vmax], [vmin, vmax], color='red')\n",
    "            ax.legend()\n",
    "            \n",
    "        return total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6762cb5-0be3-4ddf-9ba4-64c66d7aa35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ani",
   "language": "python",
   "name": "ani"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
